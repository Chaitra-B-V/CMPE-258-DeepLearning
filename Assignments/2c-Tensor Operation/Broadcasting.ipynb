{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+CPn9pzMmdEzv9OpStNrq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chaitra-B-V/CMPE-258-DeepLearning/blob/main/Assignments/2c-Tensor%20Operation/Broadcasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4T993MkpRxe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "YRBKnWzXdL1T"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Broadcasting\n",
        "\n",
        "Smaller tensors are stretched automatically inorder to fit larger tensors when running combined operations on them\n",
        "\n",
        "For example, when we multiply or add a tensor with a scalar, the scalar is broadcast to the same shape as the other argument"
      ],
      "metadata": {
        "id": "XFQSBdjWetjJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAMLVhRDVr3i",
        "outputId": "aa64842b-04d6-4534-b488-085c35dc93a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([ 8 10 12], shape=(3,), dtype=int32)\n",
            "tf.Tensor([ 8 10 12], shape=(3,), dtype=int32)\n",
            "tf.Tensor([12 15 18], shape=(3,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "x = tf.constant([4,5,6])\n",
        "y = tf.constant(2)\n",
        "z = tf.constant([3, 3, 3])\n",
        "\n",
        "#Broadcasting happens here\n",
        "print(tf.multiply(x, 2))\n",
        "print(x * y)\n",
        "print(x * z)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Broadcasting with respect to matrix multiplication\n",
        "x = tf.reshape(x,[3,1])\n",
        "y = tf.range(2,5)\n",
        "print(x, \"\\n\")\n",
        "print(y, \"\\n\")\n",
        "print(tf.multiply(x, y))\n",
        "\n",
        "a = tf.constant([2,4,6,7])\n",
        "b = tf.constant([1,2,3,4])\n",
        "print(tf.add(a,b)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZAg9730dJGx",
        "outputId": "46d0af12-2062-4bf5-bdbc-70633abe0f70"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[4]\n",
            " [5]\n",
            " [6]], shape=(3, 1), dtype=int32) \n",
            "\n",
            "tf.Tensor([2 3 4], shape=(3,), dtype=int32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[ 8 12 16]\n",
            " [10 15 20]\n",
            " [12 18 24]], shape=(3, 3), dtype=int32)\n",
            "tf.Tensor([ 3  6  9 11], shape=(4,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "String tensors \n",
        "\n",
        "String tensors are used to represent data as strings in tensors"
      ],
      "metadata": {
        "id": "WiO77FxKg0qM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#scalar string\n",
        "scalar_string_tensor = tf.constant(\"Back Propogation\")\n",
        "print(scalar_string_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acV3sKCGfgGH",
        "outputId": "56afec64-9b34-425d-f22f-83d128ac90da"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'Back Propogation', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#vector of strings\n",
        "tensor_of_strings = tf.constant([\"Back Propogation\",\n",
        "                                 \"Tensor String\",\n",
        "                                 \"Neural networks\"])\n",
        "\n",
        "print(tensor_of_strings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COamUpnJhOyQ",
        "outputId": "ff3ce306-23e3-448e-9c84-219c909479a1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([b'Back Propogation' b'Tensor String' b'Neural networks'], shape=(3,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "some string functions with tf.strings"
      ],
      "metadata": {
        "id": "jQ0xs5YahjiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting scalar string based on space\n",
        "print(tf.strings.split(scalar_string_tensor, sep=\" \"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soBn7wmghdFc",
        "outputId": "b944ed36-5057-4ab5-9c9f-a396c6a3e1e7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([b'Deep' b'Learning'], shape=(2,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting vector of strings\n",
        "print(tf.strings.split(tensor_of_strings))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhpqH9g1hp0I",
        "outputId": "c46479b2-52c2-43a2-d731-d70fc714a137"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.RaggedTensor [[b'Deep', b'Learning'],\n",
            " [b'Machine', b'Learning'],\n",
            " [b'Neural', b'networks']]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#converting string to number\n",
        "text = tf.constant(\"1 10 100\")\n",
        "print(tf.strings.to_number(tf.strings.split(text, \" \")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfZQAF_0hsUI",
        "outputId": "f2c5de1b-67f3-4506-ccc3-a394c9ce9710"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([  1.  10. 100.], shape=(3,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#converting strings to bytes, then numbers\n",
        "byte_strings = tf.strings.bytes_split(tf.constant(\"Duck\"))\n",
        "byte_ints = tf.io.decode_raw(tf.constant(\"Duck\"), tf.uint8)\n",
        "print(\"Byte strings:\", byte_strings)\n",
        "print(\"Bytes:\", byte_ints)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2XDilWYhvhZ",
        "outputId": "a852199e-7a9b-4f29-c901-2c89c3a25f5c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Byte strings: tf.Tensor([b'D' b'u' b'c' b'k'], shape=(4,), dtype=string)\n",
            "Bytes: tf.Tensor([ 68 117  99 107], shape=(4,), dtype=uint8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sparse Tensors"
      ],
      "metadata": {
        "id": "KjDoUHUJj1iW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sparse tensors are used when data is sparse. Tensorflow stores sparse data efficiently"
      ],
      "metadata": {
        "id": "Kn8A6ZkGkAgd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sparse tensors store values by index in a memory-efficient manner\n",
        "sparse_tensor = tf.sparse.SparseTensor(indices=[[0, 0], [1, 2]],\n",
        "                                       values=[1, 2],\n",
        "                                       dense_shape=[3, 4])\n",
        "print(sparse_tensor, \"\\n\")\n",
        "\n",
        "#converting sparse tensors to dense\n",
        "print(tf.sparse.to_dense(sparse_tensor))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61ca9nEoh0ga",
        "outputId": "4962753b-c65b-4ac8-f183-5fa3001717e1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SparseTensor(indices=tf.Tensor(\n",
            "[[0 0]\n",
            " [1 2]], shape=(2, 2), dtype=int64), values=tf.Tensor([1 2], shape=(2,), dtype=int32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64)) \n",
            "\n",
            "tf.Tensor(\n",
            "[[1 0 0 0]\n",
            " [0 0 2 0]\n",
            " [0 0 0 0]], shape=(3, 4), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ragged Tensors"
      ],
      "metadata": {
        "id": "K26cgStBmZTZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensors with variable number of elements along some axis is called ragged tensors. "
      ],
      "metadata": {
        "id": "I4U_1E1ImdFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#example of a ragged list(not regular)\n",
        "ragged_list = [\n",
        "    [0, 1, 2, 3],\n",
        "    [4, 5],\n",
        "    [6, 7, 8],\n",
        "    [9]]"
      ],
      "metadata": {
        "id": "QZYtsPZAk_a3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this wont work because the shape of the tensor is not normal or usual\n",
        "try:\n",
        "  tensor = tf.constant(ragged_list)\n",
        "except Exception as e:\n",
        "  print(f\"{type(e).__name__}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yh4PbrbVmm8j",
        "outputId": "4f6a9b01-3bda-48aa-ba46-3225849701f2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ValueError: Can't convert non-rectangular Python sequence to Tensor.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a ragged tensor\n",
        "ragged_tensor = tf.ragged.constant(ragged_list)\n",
        "print(ragged_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzfAOZKRmuUn",
        "outputId": "ed93a55b-1f48-42d4-8c67-b1bae8d296ec"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.RaggedTensor [[0, 1, 2, 3], [4, 5], [6, 7, 8], [9]]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ragged_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9j7-evZOmwk2",
        "outputId": "712a88e8-7a26-4e64-8ab2-066cad74972f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Named Tensor : Implementing this in Pytorch, as tensorflow does not use named dimensions for it's tensors"
      ],
      "metadata": {
        "id": "MWpwXuM5E-Oe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch"
      ],
      "metadata": {
        "id": "02HtwhDd4odY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "yQ54xhPg4s14"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Named Tensor"
      ],
      "metadata": {
        "id": "Tywx21vx0Pbl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naming the dimensions of the tensor using named tensor, this will help when performing permutations and provides extra safety"
      ],
      "metadata": {
        "id": "o2GU1gPB2dsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.zeros(2, 3, names=('N', 'C'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9lIowccmzfl",
        "outputId": "ea8610d9-d419-4cad-a88a-b1ffdcb9e944"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-eb74a8e0f1fd>:1: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at ../c10/core/TensorImpl.h:1758.)\n",
            "  torch.zeros(2, 3, names=('N', 'C'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 0., 0.]], names=('N', 'C'))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imgs = torch.randn(1, 2, 2, 3 , names=('N', 'C', 'H', 'W'))\n",
        "imgs.names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIA2pWyc2liE",
        "outputId": "def66e9c-7575-4f13-dadf-a4dac94bb9a0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('N', 'C', 'H', 'W')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "renamed_imgs = imgs.rename(H='height', W='width')\n",
        "renamed_imgs.names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8iBkl5Y2utB",
        "outputId": "d2790e68-ea4d-4782-f701-05b220caa6b1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('N', 'C', 'height', 'width')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Broadcasting\n",
        "\n",
        "Smaller tensors are stretched automatically inorder to fit larger tensors when running combined operations on them\n",
        "\n",
        "For example, when we multiply or add a tensor with a scalar, the scalar is broadcast to the same shape as the other argument"
      ],
      "metadata": {
        "id": "rwYqoqKG3EMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([4,5,6])\n",
        "y = torch.tensor(2)\n",
        "z = torch.tensor([3, 3, 3])\n",
        " \n",
        "#Broadcasting happens here\n",
        "print(torch.mul(x, 2))\n",
        "print(x * y)\n",
        "print(x * z)"
      ],
      "metadata": {
        "id": "NK2u5z36oJyd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de5f14f8-7fda-4eb8-8e9a-934f09ca6c03"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 8, 10, 12])\n",
            "tensor([ 8, 10, 12])\n",
            "tensor([12, 15, 18])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Broadcasting with respect to matrix multiplication\n",
        "x = torch.reshape(x,[3,1])\n",
        "y = torch.range(2,5)\n",
        "print(x, \"\\n\")\n",
        "print(y, \"\\n\")\n",
        "print(torch.mul(x, y))\n",
        "\n",
        "a = torch.tensor([2,4,6,7])\n",
        "b = torch.tensor([1,2,3,4])\n",
        "print(torch.add(a,b)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k30MsEHJ2LAP",
        "outputId": "dec85752-76cf-405f-ec9d-e8654c8b3004"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-9b7fc9d8080b>:3: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  y = torch.range(2,5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4],\n",
            "        [5],\n",
            "        [6]]) \n",
            "\n",
            "tensor([2., 3., 4., 5.]) \n",
            "\n",
            "tensor([[ 8., 12., 16., 20.],\n",
            "        [10., 15., 20., 25.],\n",
            "        [12., 18., 24., 30.]])\n",
            "tensor([ 3,  6,  9, 11])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "String tensors \n",
        "\n",
        "String tensors are used to represent data as strings in tensors\n",
        "\n",
        "using Tensorflow we can store string in tensors, but with pytorch, we can only use the following ways to store a string in tensor"
      ],
      "metadata": {
        "id": "qWWsD4fe3LYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "string = \"Deep Learning\"\n",
        "ascii_codes = [ord(c) for c in string]\n",
        "print(torch.tensor(ascii_codes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekSL5OyjI-Lh",
        "outputId": "8941ffae-5ab0-48fa-e778-f74ddce69864"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 68, 101, 101, 112,  32,  76, 101,  97, 114, 110, 105, 110, 103])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scalar_tensor = torch.tensor(3)\n",
        "\n",
        "string_value = \"5\"\n",
        "numerical_value = int(string_value)\n",
        "\n",
        "str_tensor = torch.tensor(numerical_value)\n",
        "print(str_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcNow2m63NWu",
        "outputId": "2dcd2531-0460-46e5-91ab-75f754b444b6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sparse Tensors\n",
        "\n",
        "Sparse tensors are used when data is sparse. Using Pytorch to store sparse data"
      ],
      "metadata": {
        "id": "Jgx5ADF03Zgd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "indices = torch.tensor([[0, 1], [1, 2], [2, 0]])\n",
        "values = torch.tensor([1, 2, 3])\n",
        "\n",
        "sparse_tensor = torch.sparse_coo_tensor(indices.t(), values, size=(3, 3))\n",
        "\n",
        "print(sparse_tensor)\n",
        "\n",
        "print(sparse_tensor[1, 2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2YXoZe83dhF",
        "outputId": "9b78cac7-4500-44c4-f412-80a7d0337404"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(indices=tensor([[0, 1, 2],\n",
            "                       [1, 2, 0]]),\n",
            "       values=tensor([1, 2, 3]),\n",
            "       size=(3, 3), nnz=3, layout=torch.sparse_coo)\n",
            "tensor(2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ragged Tensors - Nested Tensor in Pytorch\n",
        "\n",
        "Tensors with variable number of elements along some axis is called ragged tensors. In pytorch we use nested tensor for ragged tensors."
      ],
      "metadata": {
        "id": "XSHM-Ghe3fYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a, b = torch.arange(3), torch.arange(5) + 3\n",
        "nt = torch.nested.nested_tensor([a, b])\n",
        "print(\"a: \", a)\n",
        "print(\"b: \", b)\n",
        "print(\"nested tensor: \", nt)"
      ],
      "metadata": {
        "id": "Vcb9VDuf3j_p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cee076f-7a62-45a6-ad9a-1d036b1a8ccd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a:  tensor([0, 1, 2])\n",
            "b:  tensor([3, 4, 5, 6, 7])\n",
            "nested tensor:  nested_tensor([\n",
            "  tensor([0, 1, 2]),\n",
            "  tensor([3, 4, 5, 6, 7])\n",
            "])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nested/__init__.py:47: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at ../aten/src/ATen/NestedTensorImpl.cpp:175.)\n",
            "  nt = torch._nested_tensor_from_tensor_list(new_data, dtype, None, device, pin_memory)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nt.dim()"
      ],
      "metadata": {
        "id": "QPa6PR3U3lqG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5d8e1a5-d83b-4b8e-8a84-9ab42b6bec07"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}